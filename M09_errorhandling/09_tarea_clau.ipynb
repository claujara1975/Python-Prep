{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de errores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Con la clase creada en el módulo 7, tener en cuenta diferentes casos en que el código pudiera arrojar error. Por ejemplo, en la creación del objeto recibimos una lista de números enteros pero ¿qué pasa si se envía otro tipo de dato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo el módulo llamado 'herramientas_clau' y le asigno un alias 'h' utilizando la palabra clave as. \n",
    "\n",
    "import herramientas_clau as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de números enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHerramientas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhola\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# le doy un tipo de dato diferente al esperado para que me arroje error.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jarac\\OneDrive\\Escritorio\\PREP HENRY\\Python-Prep\\M09_errorhandling\\herramientas_clau.py:6\u001b[0m, in \u001b[0;36mHerramientas.__init__\u001b[1;34m(self, lista_numeros)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(lista_numeros)\u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSe ha creado una lista vacía. Se esperaba una lista de números enteros\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m lista_numeros\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de números enteros"
     ]
    }
   ],
   "source": [
    "h1 = h.Herramientas('hola')   # le doy un tipo de dato diferente al esperado para que me arroje error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = h.Herramientas([2,3,5,6,2])  # Ahora le doy una lista de números enteros y pruebo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El factorial de  2 es 2\n",
      "El factorial de  3 es 6\n",
      "El factorial de  5 es 120\n",
      "El factorial de  6 es 720\n",
      "El factorial de  2 es 2\n"
     ]
    }
   ],
   "source": [
    "h2.factorial()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En la función que hace la conversión de grados, validar que los parámetros enviados sean los esperados, de no serlo, informar cuáles son los valores esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_clau' from 'c:\\\\Users\\\\jarac\\\\OneDrive\\\\Escritorio\\\\PREP HENRY\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas_clau.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# otra forma de recargar el modulo que traemos.\n",
    "import importlib  \n",
    "importlib.reload(h)  # la función reload() de importlib recargar el módulo herramientas (previamente importado y asignado a un alias h)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.Herramientas([2,3,5,6,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los parametros de origen son: ['celsius', 'kelvin', 'farenheit']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.conversion_grados(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los parametros de origen son: ['celsius', 'kelvin', 'farenheit']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.conversion_grados(1,'celsius')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los parametros de destino son: ['celsius', 'kelvin', 'farenheit']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.conversion_grados('celsius',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35.6, 37.4, 41.0, 42.8, 35.6]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.conversion_grados('celsius','farenheit')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Importar el modulo \"unittest\" y crear los siguientes casos de pruebas sobre la clase utilizada en el punto 2<br>\n",
    "Creacion del objeto incorrecta<br>\n",
    "Creacion correcta del objeto<br>\n",
    "Metodo valor_modal()<br>\n",
    "\n",
    "Se puede usar \"raise ValueError()\" en la creación de la clase para verificar el error. Investigar sobre esta funcionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa el módulo unittest, un marco de trabajo integrado en Python para escribir y ejecutar pruebas unitarias.\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase(unittest.TestCase):\n",
    "    \n",
    "    def test_crear_objeto1(self):\n",
    "        param = 'hola'\n",
    "        self.assertRaises(ValueError, h.Herramientas, param)\n",
    "        #self.failUnlessRaises(ValueError, h.Herramientas, param)\n",
    "        \n",
    "    def test_crear_objeto2(self):\n",
    "        param = [1,2,2,5]\n",
    "        h1 = h.Herramientas(param)\n",
    "        self.assertEqual(h1.lista, param)\n",
    "\n",
    "    def test_valor_modal(self):\n",
    "        lis = [1,2,1,3]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        moda, veces = h1.valor_modal(False)\n",
    "        moda = [moda]\n",
    "        moda.append(veces)\n",
    "        resultado = [1, 2]\n",
    "        self.assertEqual(moda, resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 0 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x18fec085410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chequea que arroje que hay un error en el primer test\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x18fec035690>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chequea que arroje que hay un error en el primer y segundo test\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal) ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_valor_modal (__main__.ProbandoMiClase.test_valor_modal)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jarac\\AppData\\Local\\Temp\\ipykernel_21080\\2623554725.py\", line 16, in test_valor_modal\n",
      "    moda, veces = h1.valor_modal(False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jarac\\OneDrive\\Escritorio\\PREP HENRY\\Python-Prep\\M09_errorhandling\\herramientas_clau.py\", line 19, in valor_modal\n",
      "    for num in lista:\n",
      "TypeError: 'bool' object is not iterable\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.009s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x18fec092c50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chequea que arroje que hay un error en los 3 test\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Probar una creación incorrecta y visualizar la salida del \"raise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de números enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h2 \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHerramientas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malgo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jarac\\OneDrive\\Escritorio\\PREP HENRY\\Python-Prep\\M09_errorhandling\\herramientas_clau.py:6\u001b[0m, in \u001b[0;36mHerramientas.__init__\u001b[1;34m(self, lista_numeros)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(lista_numeros)\u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSe ha creado una lista vacía. Se esperaba una lista de números enteros\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista \u001b[38;5;241m=\u001b[39m lista_numeros\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de números enteros"
     ]
    }
   ],
   "source": [
    "h2 = h.Herramientas('algo')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Agregar casos de pruebas para el método verifica_primos() realizando el cambio en la clase, para que devuelva una lista de True o False en función de que el elemento en la posisicón sea o no primo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase2(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_primos1(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        primos = h1.verifica_primo()\n",
    "        primos_esperado = [True, True, False, False, True]\n",
    "        self.assertEqual(primos, primos_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False, False, True]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3 = h.Herramientas([2,3,8,10,13])\n",
    "h3.verifica_primo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_clau' from 'c:\\\\Users\\\\jarac\\\\OneDrive\\\\Escritorio\\\\PREP HENRY\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas_clau.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal) ... ERROR\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2.test_verifica_primos1) ... ok\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_valor_modal (__main__.ProbandoMiClase.test_valor_modal)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jarac\\AppData\\Local\\Temp\\ipykernel_21080\\2623554725.py\", line 16, in test_valor_modal\n",
      "    moda, veces = h1.valor_modal(False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jarac\\OneDrive\\Escritorio\\PREP HENRY\\Python-Prep\\M09_errorhandling\\herramientas_clau.py\", line 21, in valor_modal\n",
      "    for num in lista:\n",
      "TypeError: 'bool' object is not iterable\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.016s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x18fec0e4690>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Agregar casos de pruebas para el método conversion_grados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase3(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_conversion1(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        grados = h1.conversion_grados('celsius','farenheit')\n",
    "        grados_esperado = [35.6, 37.4, 46.4, 50.0, 55.4]\n",
    "        self.assertEqual(grados, grados_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_clau' from 'c:\\\\Users\\\\jarac\\\\OneDrive\\\\Escritorio\\\\PREP HENRY\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas_clau.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "h4 = h.Herramientas([35.6, 37.4, 46.4, 50.0, 55.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96.08000000000001, 99.32, 115.52, 122.0, 131.72]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h4.conversion_grados('celsius','farenheit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal) ... ERROR\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2.test_verifica_primos1) ... ok\n",
      "test_verifica_conversion1 (__main__.ProbandoMiClase3.test_verifica_conversion1) ... ok\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_valor_modal (__main__.ProbandoMiClase.test_valor_modal)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jarac\\AppData\\Local\\Temp\\ipykernel_21080\\2623554725.py\", line 16, in test_valor_modal\n",
      "    moda, veces = h1.valor_modal(False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jarac\\OneDrive\\Escritorio\\PREP HENRY\\Python-Prep\\M09_errorhandling\\herramientas_clau.py\", line 21, in valor_modal\n",
      "    for num in lista:\n",
      "TypeError: 'bool' object is not iterable\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.010s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x18fec092290>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Agregar casos de pruebas para el método factorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase4(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_factorial(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        factorial = h1.factorial()\n",
    "        factorial_esperado = [2, 6, 40320, 3628800, 6227020800]\n",
    "        self.assertEqual(factorial, factorial_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 6, 40320, 3628800, 6227020800]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h4 = h.Herramientas([2,3,8,10,13])\n",
    "h4.factorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_clau' from 'c:\\\\Users\\\\jarac\\\\OneDrive\\\\Escritorio\\\\PREP HENRY\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas_clau.py'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal) ... ERROR\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2.test_verifica_primos1) ... ok\n",
      "test_verifica_conversion1 (__main__.ProbandoMiClase3.test_verifica_conversion1) ... ok\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_valor_modal (__main__.ProbandoMiClase.test_valor_modal)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jarac\\AppData\\Local\\Temp\\ipykernel_21080\\2623554725.py\", line 16, in test_valor_modal\n",
      "    moda, veces = h1.valor_modal(False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jarac\\OneDrive\\Escritorio\\PREP HENRY\\Python-Prep\\M09_errorhandling\\herramientas_clau.py\", line 21, in valor_modal\n",
      "    for num in lista:\n",
      "TypeError: 'bool' object is not iterable\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.010s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x18feafd9550>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c85384e4cb51c8b72350f3a8712cc8351fdc3955e32a27f9b60c6242ab125f01"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
